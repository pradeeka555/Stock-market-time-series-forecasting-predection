{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy matplotlib scikit-learn tensorflow gradio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhuGVi-WkFs_",
        "outputId": "a2f49304-ad7d-4d13-f4de-9cc8ed6f100e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.46.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.75.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.116.2)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.13.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.13.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.3)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.9)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.0)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.17.4)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.19.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (1.1.10)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Robust Time-Series Forecasting Gradio App\n",
        "- Input: company name (must exist in CSV).\n",
        "- Output: performance_dashboard.png, forecast_plot.png, and a summary message.\n",
        "Place this file alongside your dataset (default path /content/synthetic_stock_data.csv)\n",
        "and optional model.h5 (if you want to use a pre-saved LSTM).\n",
        "\"\"\"\n",
        "\n",
        "import os, sys, subprocess, warnings, io\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ---------- helper: resilient imports ----------\n",
        "def try_import(name, import_from=None):\n",
        "    try:\n",
        "        if import_from:\n",
        "            m = __import__(import_from, fromlist=[name])\n",
        "            return getattr(m, name), None\n",
        "        else:\n",
        "            m = __import__(name)\n",
        "            return m, None\n",
        "    except Exception as e:\n",
        "        return None, e\n",
        "\n",
        "# optional forecasting libs\n",
        "auto_arima = None\n",
        "arima_available = True\n",
        "obj, err = try_import('auto_arima', import_from='pmdarima')\n",
        "if err:\n",
        "    arima_available = False\n",
        "else:\n",
        "    auto_arima = obj\n",
        "\n",
        "Prophet = None\n",
        "prophet_available = True\n",
        "obj, err = try_import('Prophet', import_from='prophet')\n",
        "if err:\n",
        "    obj2, err2 = try_import('Prophet', import_from='fbprophet')\n",
        "    if obj2:\n",
        "        Prophet = obj2\n",
        "    else:\n",
        "        prophet_available = False\n",
        "else:\n",
        "    Prophet = obj\n",
        "\n",
        "# plotting libs\n",
        "try:\n",
        "    import matplotlib.pyplot as plt\n",
        "except Exception:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"matplotlib\"])\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "# core libs\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# reporting / images (FPDF/Openpyxl not needed inside Gradio display)\n",
        "import gradio as gr\n",
        "\n",
        "# reproducibility\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# ---------- load dataset (adjust path if needed) ----------\n",
        "DATA_PATHS = [\n",
        "    \"synthetic_stock_data.csv\",\n",
        "    \"/content/synthetic_stock_data.csv\",\n",
        "    \"/mnt/data/synthetic_stock_data.csv\",\n",
        "    \"stock_data.csv\"\n",
        "]\n",
        "dataset_path = None\n",
        "for p in DATA_PATHS:\n",
        "    if os.path.exists(p):\n",
        "        dataset_path = p\n",
        "        break\n",
        "\n",
        "if dataset_path is None:\n",
        "    raise FileNotFoundError(\"Couldn't find dataset. Place CSV as 'synthetic_stock_data.csv' or update DATA_PATHS.\")\n",
        "\n",
        "raw_df = pd.read_csv(dataset_path)\n",
        "raw_df.columns = [c.lower() for c in raw_df.columns]\n",
        "\n",
        "# ensure minimal required columns exist\n",
        "if not any(c in raw_df.columns for c in [\"date\"]):\n",
        "    # assume first column is date-like\n",
        "    pass\n",
        "\n",
        "# normalize column names\n",
        "date_col = \"date\" if \"date\" in raw_df.columns else raw_df.columns[0]\n",
        "close_col = \"close\" if \"close\" in raw_df.columns else raw_df.select_dtypes(include=np.number).columns[-1]\n",
        "company_col = \"company\" if \"company\" in raw_df.columns else None\n",
        "\n",
        "# rename canonical\n",
        "raw_df = raw_df.rename(columns={date_col: \"Date\", close_col: \"Close\"})\n",
        "if company_col:\n",
        "    raw_df = raw_df.rename(columns={company_col: \"Company\"})\n",
        "else:\n",
        "    # create a dummy company column if missing (so user can query that name)\n",
        "    raw_df[\"Company\"] = \"COMPANY\"\n",
        "\n",
        "# parse date and sort\n",
        "raw_df[\"Date\"] = pd.to_datetime(raw_df[\"Date\"], errors=\"coerce\")\n",
        "raw_df[\"Close\"] = pd.to_numeric(raw_df[\"Close\"], errors=\"coerce\")\n",
        "raw_df = raw_df.dropna(subset=[\"Date\", \"Close\"]).sort_values(\"Date\").reset_index(drop=True)\n",
        "\n",
        "# ---------- helper functions ----------\n",
        "def evaluate_model(y_true, y_pred, name=\"Model\"):\n",
        "    # align lengths\n",
        "    y_true = np.asarray(y_true).ravel()\n",
        "    y_pred = np.asarray(y_pred).ravel()\n",
        "    minlen = min(len(y_true), len(y_pred))\n",
        "    if minlen == 0:\n",
        "        return {\"Model\": name, \"MAE\": np.nan, \"RMSE\": np.nan}\n",
        "    y_true = y_true[:minlen]\n",
        "    y_pred = y_pred[:minlen]\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    return {\"Model\": name, \"MAE\": mae, \"RMSE\": rmse}\n",
        "\n",
        "def save_performance_plot(results_list, outpath=\"performance_dashboard.png\"):\n",
        "    df = pd.DataFrame(results_list)\n",
        "    # drop nan rows\n",
        "    df = df.dropna(subset=[\"MAE\",\"RMSE\"], how=\"all\")\n",
        "    if df.empty:\n",
        "        # create placeholder\n",
        "        plt.figure(figsize=(6,3))\n",
        "        plt.text(0.5, 0.5, \"No performance metrics\", ha=\"center\", va=\"center\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.savefig(outpath, bbox_inches=\"tight\", dpi=150)\n",
        "        plt.close()\n",
        "        return outpath\n",
        "    df = df.set_index(\"Model\")[[\"MAE\",\"RMSE\"]]\n",
        "    ax = df.plot(kind=\"bar\", figsize=(8,4), rot=0)\n",
        "    ax.set_ylabel(\"Error\")\n",
        "    ax.set_title(\"Model Performance (MAE & RMSE)\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(outpath, dpi=150)\n",
        "    plt.close()\n",
        "    return outpath\n",
        "\n",
        "def save_forecast_plot(df_train, df_test, preds_dict, outpath=\"forecast_plot.png\"):\n",
        "    plt.figure(figsize=(12,5))\n",
        "    plt.plot(df_train[\"Date\"], df_train[\"Close\"], label=\"Train\")\n",
        "    plt.plot(df_test[\"Date\"], df_test[\"Close\"], label=\"Test\", color=\"black\")\n",
        "    for name, series in preds_dict.items():\n",
        "        # ensure series length matches df_test length or pad with nan\n",
        "        arr = np.asarray(series)\n",
        "        if len(arr) < len(df_test):\n",
        "            arr = np.concatenate([np.full(len(df_test)-len(arr), np.nan), arr]) if len(arr)>0 else np.full(len(df_test), np.nan)\n",
        "        plt.plot(df_test[\"Date\"], arr, label=name)\n",
        "    plt.title(\"Forecast Comparison\")\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.ylabel(\"Close\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(outpath, dpi=150)\n",
        "    plt.close()\n",
        "    return outpath\n",
        "\n",
        "def make_sequences(data, window):\n",
        "    X, y = [], []\n",
        "    for i in range(window, len(data)):\n",
        "        X.append(data[i-window:i, 0])\n",
        "        y.append(data[i, 0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "def safe_float_array(a):\n",
        "    return np.asarray(a).astype(float)\n",
        "\n",
        "# ---------- main forecasting routine for a company ----------\n",
        "def run_forecast_for_company(company_name: str, use_saved_lstm=True, lstm_epochs=6):\n",
        "    # sanitize input\n",
        "    company_name = (company_name or \"\").strip()\n",
        "    if not company_name:\n",
        "        return None, None, \"‚ùå Please enter a company name.\"\n",
        "\n",
        "    # filter dataset (case-insensitive)\n",
        "    df_company = raw_df[raw_df[\"Company\"].str.lower() == company_name.lower()].copy()\n",
        "    if df_company.empty:\n",
        "        # try partial match\n",
        "        df_company = raw_df[raw_df[\"Company\"].str.lower().str.contains(company_name.lower())].copy()\n",
        "\n",
        "    if df_company.empty:\n",
        "        return None, None, f\"‚ùå Company '{company_name}' not found in dataset.\"\n",
        "\n",
        "    # reset index & ensure sorted\n",
        "    df_company = df_company.sort_values(\"Date\").reset_index(drop=True)\n",
        "\n",
        "    n = len(df_company)\n",
        "    # pick initial SEQ\n",
        "    SEQ = 10\n",
        "    # if dataset small, reduce SEQ dynamically\n",
        "    if n < SEQ + 5:\n",
        "        SEQ = max(3, max(1, int(n * 0.12)))  # keep small but meaningful\n",
        "    if SEQ >= n:\n",
        "        SEQ = max(1, n - 1)\n",
        "\n",
        "    # TEST_DAYS: at most 180 or 20% of data but ensure there's at least one training row\n",
        "    TEST_DAYS = min(180, max(1, int(n * 0.2)))\n",
        "    if n - TEST_DAYS < 1:\n",
        "        TEST_DAYS = max(1, n - 1)\n",
        "\n",
        "    # scaled data and sequences\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled = scaler.fit_transform(df_company[[\"Close\"]].values)\n",
        "    X_all, y_all = make_sequences(scaled, SEQ)\n",
        "    if len(X_all) == 0:\n",
        "        return None, None, \"‚ùå Not enough rows to build sequences. Need at least (SEQ+1) rows.\"\n",
        "\n",
        "    # Ensure TEST_DAYS <= len(X_all)\n",
        "    if TEST_DAYS > len(X_all):\n",
        "        TEST_DAYS = max(1, len(X_all) // 2)\n",
        "\n",
        "    # train/test for sequences\n",
        "    X_train = X_all[:-TEST_DAYS] if len(X_all) > TEST_DAYS else X_all[:0]\n",
        "    y_train = y_all[:-TEST_DAYS] if len(y_all) > TEST_DAYS else y_all[:0]\n",
        "    X_test = X_all[-TEST_DAYS:]\n",
        "    y_test = y_all[-TEST_DAYS:]\n",
        "\n",
        "    # Map df_train/df_test (by Date) for plotting: df_test should correspond to last TEST_DAYS rows in df_company starting at index SEQ\n",
        "    df_test = df_company.iloc[-TEST_DAYS:].copy().reset_index(drop=True)\n",
        "    df_train = df_company.iloc[: len(df_company) - TEST_DAYS].copy().reset_index(drop=True)\n",
        "\n",
        "    preds = {}\n",
        "    results = []\n",
        "\n",
        "    # --- Baseline: Naive (last value from df_train) ---\n",
        "    if len(df_train) >= 1:\n",
        "        last_val = df_train[\"Close\"].iloc[-1]\n",
        "    else:\n",
        "        last_val = df_company[\"Close\"].iloc[0]\n",
        "    naive_pred = np.repeat(last_val, len(df_test))\n",
        "    preds[\"Naive\"] = naive_pred\n",
        "    results.append(evaluate_model(df_test[\"Close\"].values, naive_pred, \"Naive\"))\n",
        "\n",
        "    # --- Baseline: MA(window) ---\n",
        "    ma_window = min(7, max(1, len(df_train)))\n",
        "    if len(df_train) >= ma_window:\n",
        "        ma_last = df_train[\"Close\"].rolling(ma_window).mean().dropna()\n",
        "        ma_last_val = ma_last.iloc[-1] if not ma_last.empty else df_train[\"Close\"].iloc[-1] if len(df_train) else df_company[\"Close\"].mean()\n",
        "    else:\n",
        "        ma_last_val = df_train[\"Close\"].iloc[-1] if len(df_train) else df_company[\"Close\"].mean()\n",
        "    ma_pred = np.repeat(ma_last_val, len(df_test))\n",
        "    preds[f\"MA({ma_window})\"] = ma_pred\n",
        "    results.append(evaluate_model(df_test[\"Close\"].values, ma_pred, f\"MA({ma_window})\"))\n",
        "\n",
        "    # --- ARIMA (if available & enough training data) ---\n",
        "    if arima_available and auto_arima and len(df_train) >= 12:\n",
        "        try:\n",
        "            arima_model = auto_arima(df_train[\"Close\"].values, seasonal=False, suppress_warnings=True, error_action=\"ignore\")\n",
        "            arima_forecast = arima_model.predict(n_periods=len(df_test))\n",
        "            preds[\"ARIMA\"] = arima_forecast\n",
        "            results.append(evaluate_model(df_test[\"Close\"].values, arima_forecast, \"ARIMA\"))\n",
        "        except Exception as e:\n",
        "            # skip ARIMA on errors\n",
        "            print(\"ARIMA error:\", e)\n",
        "\n",
        "    # --- Prophet (if available & enough data) ---\n",
        "    if prophet_available and Prophet and len(df_train) >= 10:\n",
        "        try:\n",
        "            prophet_df = df_train[[\"Date\",\"Close\"]].rename(columns={\"Date\":\"ds\",\"Close\":\"y\"})\n",
        "            model_prophet = Prophet(daily_seasonality=True)\n",
        "            model_prophet.fit(prophet_df)\n",
        "            future = pd.DataFrame(df_test[\"Date\"]).rename(columns={\"Date\":\"ds\"})\n",
        "            prophet_pred = model_prophet.predict(future)[\"yhat\"].values\n",
        "            preds[\"Prophet\"] = prophet_pred\n",
        "            results.append(evaluate_model(df_test[\"Close\"].values, prophet_pred, \"Prophet\"))\n",
        "        except Exception as e:\n",
        "            print(\"Prophet error:\", e)\n",
        "\n",
        "    # --- LSTM: use saved model.h5 if available and compatible, else train a lightweight on-the-fly model if dataset permits ---\n",
        "    lstm_used = False\n",
        "    # Try use external model.h5 only if shape compatibility likely OK\n",
        "    if use_saved_lstm and os.path.exists(\"model.h5\"):\n",
        "        try:\n",
        "            loaded = load_model(\"model.h5\")\n",
        "            # loaded expects (batch, seq, 1). We'll attempt prediction using X_test if shapes align.\n",
        "            if X_test.shape[1] == loaded.input_shape[1]:\n",
        "                y_pred_scaled = loaded.predict(X_test.reshape((-1, X_test.shape[1], 1)))\n",
        "                y_pred = scaler.inverse_transform(y_pred_scaled).ravel()\n",
        "                preds[\"LSTM\"] = y_pred\n",
        "                results.append(evaluate_model(df_test[\"Close\"].values[:len(y_pred)], y_pred, \"LSTM\"))\n",
        "                lstm_used = True\n",
        "            else:\n",
        "                # mismatch sequence length -> will attempt on-the-fly train\n",
        "                print(\"Saved model sequence mismatch: saved seq\", loaded.input_shape[1], \"data seq\", X_test.shape[1])\n",
        "        except Exception as e:\n",
        "            print(\"Could not load model.h5:\", e)\n",
        "\n",
        "    # On-the-fly LSTM training (only if not used saved and there's enough training examples)\n",
        "    if (not lstm_used) and len(X_train) >= 5:\n",
        "        try:\n",
        "            # prepare shapes\n",
        "            X_train_tf = X_train.reshape((-1, X_train.shape[1], 1))\n",
        "            X_test_tf = X_test.reshape((-1, X_test.shape[1], 1))\n",
        "            model = Sequential([LSTM(64, input_shape=(X_train_tf.shape[1],1)), Dropout(0.2), Dense(1)])\n",
        "            model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "            # small epochs to keep interactive time low\n",
        "            model.fit(X_train_tf, y_train, epochs=max(3, lstm_epochs), batch_size=16, verbose=0)\n",
        "            y_pred_scaled = model.predict(X_test_tf)\n",
        "            y_pred = scaler.inverse_transform(y_pred_scaled).ravel()\n",
        "            preds[\"LSTM\"] = y_pred\n",
        "            results.append(evaluate_model(df_test[\"Close\"].values[:len(y_pred)], y_pred, \"LSTM\"))\n",
        "            # optionally save quick model (commented)\n",
        "            # model.save(\"model_quick.h5\")\n",
        "            lstm_used = True\n",
        "        except Exception as e:\n",
        "            print(\"On-the-fly LSTM failed:\", e)\n",
        "\n",
        "    # create result images (performance & forecast)\n",
        "    perf_path = save_performance_plot(results, outpath=\"performance_dashboard.png\")\n",
        "    fcst_path = save_forecast_plot(df_train, df_test, preds, outpath=\"forecast_plot.png\")\n",
        "\n",
        "    last_date = df_test[\"Date\"].max().strftime(\"%Y-%m-%d\")\n",
        "    message = f\"‚úÖ Generates performance dashboard & forecast plots with Date up to {last_date} (Company: {company_name}, rows: {n})\"\n",
        "\n",
        "    return perf_path, fcst_path, message\n",
        "\n",
        "# ---------- Gradio UI ----------\n",
        "title = \"üìà Time Series Forecast Dashboard (by Company)\"\n",
        "desc = \"Enter company name from the dataset. The app filters rows for that company, runs quick forecasts and returns performance & forecast plots.\"\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=run_forecast_for_company,\n",
        "    inputs=gr.Textbox(lines=1, placeholder=\"Enter company name (case-insensitive)\"),\n",
        "    outputs=[gr.Image(type=\"filepath\", label=\"Performance Dashboard\"),\n",
        "             gr.Image(type=\"filepath\", label=\"Forecast Plot\"),\n",
        "             gr.Textbox(label=\"Message\")],\n",
        "    title=title,\n",
        "    description=desc,\n",
        "    allow_flagging=\"never\",\n",
        "    examples=[]\n",
        ")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    iface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "IgqiwT63vCet",
        "outputId": "a9b69928-2303-45fe-bbf0-fcd7107430b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a844faf29d099b5952.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a844faf29d099b5952.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}